---
title: "Variable importance"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("R/_startup.R")
ck37r::load_all_code("R", verbose = TRUE)
startup(auto_install = FALSE, verbose = FALSE)
```

## Load data

```{r load_data}
load(paste0(data_dir, "import-data-imputed.RData"))
names(data)
# 116,711 obs and 102 variables
dim(data)
# 74 covariates
length(vars$covariates)
vars$covariates

# ads60d
(outcome_field = vars$outcomes[1])
```

## Random Forest 

```{r rf_fit}
set.seed(1, "L'Ecuyer-CMRG")

# mlr wants covariates and outcome to be in the same dataframe.

# For classification RF needs Y to be a factor.
# We use the best mtry based on the CV.SL results from the final prediction library.
# Takes ~35 minutes on the server.
(rf_time = system.time({
  # Ranger uses all available threads by default, nice.
  y = as.factor(data[[vars$outcomes[1]]]) 
  rf = ranger::ranger(y ~ . ,
                      # We remove these due to the inclusion of EDACS and HEART raw scores,
                      # and the danger of including both causing a masking effect.
                      data = data[, setdiff(vars$covariates,
                                            c("edacs_high", "heart_high"))],
                      num.threads = get_cores(),
                      #num.threads = RhpcBLASctl::get_num_cores(),
                      # Need this option for OOB curve analysis.
                      keep.inbag = TRUE,
                      num.trees = 4000,
                      # Could also do importance = "impurity".
                      importance = "permutation",
                      min.node.size = 5L,
                      mtry = 4L)
}))
save(rf, file = paste0(data_dir, "vim-rf.RData"))
#load(paste0(data_dir, "vim-rf.RData"))

rf_imp = ranger::importance(rf)
# Sort by descending importance.
rf_imp = rf_imp[order(rf_imp, decreasing = TRUE)]

# Review top 10 real quick.
round(rf_imp, 4)[1:10]

print_imp = as.data.frame(rf_imp[1:40, drop = FALSE])

print_imp

# Mean decrease in accuracy.
colnames(print_imp) = c("mean_dec_acc")

print_imp$var = rownames(print_imp)
print_imp2 = print_imp

# Merge in clean variable name
print_imp2 = dplyr::left_join(print_imp2, var_df[, c("var", "name")], by = "var")

# Replace raw variable name with the clean name.
print_imp2$var = print_imp2$name

# Clear out the extra copy of the clean name.
print_imp2$name = NULL

# Add ranking to the rownames.
print_imp2$var = paste0(1:nrow(print_imp2), ". ", print_imp2$var)
print_imp2
colnames(print_imp2)[2] = "Variable"
#colnames(print_imp2)[3] = "Description"

# Reverse ordering of columns.
print_imp2 = print_imp2[, c(2, 1)]

#
#print_imp2 = print_imp2[, c("Variable", "Mean Decrease Accuracy (%)")]#, "Description")]
#print_imp2 = print_imp2[, c("Variable", "\thead{Mean\\{}Decrease\\{}Accuracy (%)}")]#, "Description")]
print_imp2

# Convert to a percentage.
print_imp2[, 2] = print_imp2[, 2] * 100

# Manually escape variable names.
#print_imp2$Variable = gsub("_", "\\_", print_imp2$Variable, fixed = TRUE)
#print_imp2

colnames(print_imp2)[1] = "\\thead{Variable}"
colnames(print_imp2)[2] = "\\thead{Mean\\\\{}Decrease\\\\{}Accuracy (\\%)}"


# Top 20.
(kab_table =
    kable(print_imp2[1:20, ],
          format = "latex",
          digits = c(0, 3),
          booktabs = TRUE,
          escape = FALSE,
          row.names = FALSE))
cat(kab_table %>% kable_styling(latex_options = "striped"),
    file = "tables/vim-rf-top20.tex")
```

### RF: convergence plot

```{r rf_oob_curve}
library(mlr)
library(OOBCurve)

#lrn = makeLearner("classif.ranger", keep.inbag = TRUE, par.vals = list(num.trees = 3000))
# mod = train(lrn, task)

# outcome needs to be a factor.

oob_data = data[, c(vars$outcomes[1],
                    setdiff(vars$covariates,
                            NULL #c("edacs_high", "heart_high")
                            ))]
oob_data[[vars$outcomes[1]]] = as.factor(data[[vars$outcomes[1]]])


task = makeClassifTask(data = oob_data, target = vars$outcomes[1])
# Current package has a bug such that multiple measures have to be specified.
# We aren't using the Brier score though.
# These results could be averaged over multiple random shufflings
# of the tree ordering. Would give a more accurate, smoother curve.
system.time({
results = OOBCurve(rf, measures = list(mlr::auc, mlr::brier), task = task,
                   data = oob_data)
})

# Look at the OOB AUC with the maximum number of trees.
(rf_auc = results$auc[length(results$auc)])

# Can zoom in to certain segments of the forest indexed by an ntree range.
tree_start = 1
#tree_start = 10
tree_end = length(results$auc)
x_span = seq(tree_start, tree_end)
y_span = results$auc[x_span]

ggplot(mapping = aes(x = x_span, y = y_span)) + geom_line() + theme_minimal() +
  # 10,000 gives a square plot; lower to give a more rectangular plot.
  coord_fixed(ratio = 3) + 
  scale_y_continuous(expand = c(0, 0), limits = c(0.5, 0.94)) +
  scale_x_log10(#expand = c(0, 0),
                breaks = c(1, 3, 10, 30, 100, 300, 1000, 3000),
                minor_breaks = NULL) +
  labs(x = "Trees in the random forest", y = "Out of Bag AUC")#,
       #title = "Random Forest AUC on out-of-bag data")
ggsave("visuals/rf-error-rate-by-trees.png",
       width = 7, height = 3)

ggsave("visuals/rf-error-rate-by-trees.pdf",
       width = 7, height = 3)

```

## xgboost

```{r vim_xgboost}
library(xgboost)

table(data[[vars$outcomes[1]]])

vars$covariates

system.time({
  xgb =
    xgboost(data = data.matrix(data[, vars$covariates]),
            label = data[[vars$outcomes[1]]],
            #max_depth = 4L,
            #eta = 0.01, 
            params = list(min_child_weight = 10,
                          max_depth = 4,
                          eta = 0.01),
            # Use up to 50% of CPU cores.
            nthread = floor(RhpcBLASctl::get_num_cores() / 2),
            nrounds = 1000L,
            objective = "rank:pairwise")
})

# NOTE: this returns a data.table
importance = xgb.importance(feature_names = vars$covariates, model = xgb)
head(importance)

class(importance)
head(importance)

xgb_imp = importance
data.table::setDF(xgb_imp)
xgb_imp = dplyr::left_join(xgb_imp, name_df, by = c("Feature" = "var"))
head(xgb_imp)

xgb_imp = xgb_imp %>% dplyr::rename("Variable" = "name") %>% as.data.frame()

xgb_imp = xgb_imp[, c("Variable", "Gain")]

# Add ranking to variables.

xgb_imp$Variable = paste0(seq(nrow(xgb_imp)), ". ", xgb_imp$Variable)

head(xgb_imp)


colnames(xgb_imp)[1] = "\\thead{Variable}"
colnames(xgb_imp)[2] = "\\thead{Gain}"

(kab_tab = kable(xgb_imp[1:20, ], 
                 digits = c(0, 4),
                 escape = FALSE,
                 format = "latex", booktabs = TRUE, row.names = FALSE))
cat(kab_tab %>% kable_styling(latex_options = "striped"),
    file = "tables/vim-xgb.tex")


p = xgb.ggplot.importance(importance[1:32]) +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.margin = ggplot2::margin(1.5, 3, 2, 2), #trbl
        panel.background = element_rect(fill = "white", color = "gray50"),
        plot.background = element_rect(fill = "gray95"),
        legend.box.background = element_rect(fill = "gray97", color = "gray70"), 
        legend.position = c(0.9, 0.25)) +
  labs(title = "Variable importance: xgboost")
p2 = gginnards::delete_layers(p,"GeomBar") 
p2 + geom_col(aes(fill = Cluster), width = 1)#, stat = "identity")

#ggsave("visuals/vim-xgb.png", width = 8, height = 6)
ggsave("visuals/vim-xgb.pdf", width = 8, height = 6)


save(xgb, importance, xgb_imp,
     file = "data/vim-xgboost.RData")
```
